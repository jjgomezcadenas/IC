{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal vs. background classification with NEW full MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.patches         import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy  as np\n",
    "import random as rd\n",
    "import tables as tb\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "from __future__  import print_function\n",
    "from scipy.stats import threshold\n",
    "\n",
    "from keras.models               import Model, load_model\n",
    "from keras.layers               import Input, Dense, MaxPooling3D, Convolution3D, Activation, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers           import SGD, Adam, Nadam         \n",
    "#from keras.callbacks            import ReduceLROnPlateau !!!!!\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core          import Flatten\n",
    "from keras                      import callbacks\n",
    "from keras.regularizers         import l2, activity_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jrenner/data/classification/NEW_training_MC_si_nopadding_nonorm_einfo.h5 (File) ''\n",
      "Last modif.: 'Tue Dec 13 15:14:17 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/energies (EArray(26242, 30), blosc(9)) ''\n",
      "/maps (EArray(26242, 48, 48, 30), blosc(9)) ''\n",
      "\n",
      "/home/jrenner/data/classification/NEW_training_MC_bg_nopadding_nonorm_einfo.h5 (File) ''\n",
      "Last modif.: 'Tue Dec 13 15:14:10 2016'\n",
      "Object Tree: \n",
      "/ (RootGroup) ''\n",
      "/energies (EArray(19089, 30), blosc(9)) ''\n",
      "/maps (EArray(19089, 48, 48, 30), blosc(9)) ''\n",
      "\n",
      "Concatenating datasets...\n",
      "Reshaping...\n",
      "Prepared 34000 training events and 4000 validation events.\n"
     ]
    }
   ],
   "source": [
    "Ntrain = 17000     # number of training events per sample\n",
    "Ntot = 19000\n",
    "\n",
    "# Signal events.\n",
    "#s_dat = tb.open_file('/home/jrenner/data/classification/NEW_training_MC_si_nst_nonorm.h5', 'r')\n",
    "s_dat = tb.open_file('/home/jrenner/data/classification/NEW_training_MC_si_nopadding_nonorm_einfo.h5', 'r')\n",
    "print(s_dat)\n",
    "s_array = np.array(s_dat.root.maps)\n",
    "x_t = s_array[:Ntrain]\n",
    "x_v = s_array[Ntrain:Ntot]\n",
    "y_t = np.ones([Ntrain, 1])\n",
    "y_v = np.ones([Ntot-Ntrain, 1])\n",
    "\n",
    "s_earray = np.array(s_dat.root.energies)\n",
    "\n",
    "# Background events.\n",
    "#b_dat = tb.open_file('/home/jrenner/data/classification/NEW_training_MC_bg_nst_nonorm.h5', 'r')\n",
    "b_dat = tb.open_file('/home/jrenner/data/classification/NEW_training_MC_bg_nopadding_nonorm_einfo.h5', 'r')\n",
    "print(b_dat)\n",
    "b_array = np.array(b_dat.root.maps)\n",
    "print(\"Concatenating datasets...\")\n",
    "x_t = np.concatenate([x_t, b_array[:Ntrain]])\n",
    "x_v = np.concatenate([x_v, b_array[Ntrain:Ntot]])\n",
    "y_bt = np.zeros([Ntrain, 1])\n",
    "y_t = np.concatenate([y_t, y_bt])\n",
    "y_bv = np.zeros([Ntot-Ntrain, 1])\n",
    "y_v = np.concatenate([y_v, y_bv])\n",
    "\n",
    "b_earray = np.array(b_dat.root.energies)\n",
    "\n",
    "# Normalize\n",
    "#mval = max(np.max(s_array),np.max(b_array))\n",
    "#muval = np.mean(s_array)\n",
    "#sval = np.std(s_array)\n",
    "#print(\"Normalizing with max value of\", mval, \"(mean of\", muval, \"; sigma of \", sval, \")\")\n",
    "#x_t /= sval\n",
    "#x_v /= sval\n",
    "\n",
    "# Include the final dimension (single-channel).\n",
    "print(\"Reshaping...\")\n",
    "#x_t = np.expand_dims(x_t, axis=1)\n",
    "#x_v = np.expand_dims(x_v, axis=1)\n",
    "x_t = np.reshape(x_t, (len(x_t), 48, 48, 30, 1))\n",
    "x_v = np.reshape(x_v, (len(x_v), 48, 48, 30, 1))\n",
    "print(\"Prepared\", len(x_t), \"training events and\", len(x_v), \"validation events.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove noise.\n",
    "nthr = 5.0e-5\n",
    "inoise = x_t < nthr\n",
    "x_t[inoise] = 0\n",
    "\n",
    "inoise = x_v < nthr\n",
    "x_v[inoise] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 48, 48, 30, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_4 (Convolution3D)  (None, 16, 16, 6, 64) 13888       input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling3d_3 (MaxPooling3D)    (None, 8, 8, 2, 64)   0           convolution3d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_3 (BatchNorma (None, 8, 8, 2, 64)   128         maxpooling3d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_5 (Convolution3D)  (None, 8, 8, 2, 16)   1040        batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "convolution3d_6 (Convolution3D)  (None, 8, 8, 2, 32)   4128        convolution3d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_4 (BatchNorma (None, 8, 8, 2, 32)   64          convolution3d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling3d_4 (MaxPooling3D)    (None, 4, 4, 1, 32)   0           batchnormalization_4[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 512)           0           maxpooling3d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 32)            16416       flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 32)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             33          dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 35697\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lmodel = True\n",
    "    \n",
    "with K.tf.device('/gpu:1'):\n",
    "    \n",
    "    if(lmodel):\n",
    "        incep = load_model('models/conv3d_classifier_stc.h5')\n",
    "    else:\n",
    "        K.set_session(K.tf.Session(config=K.tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)))\n",
    "\n",
    "        inputs = Input(shape=(48, 48, 30, 1))\n",
    "        cinputs = Convolution3D(64, 6, 6, 6, border_mode='same', subsample=(3, 3, 5), activation='relu',init='lecun_uniform', W_regularizer=l2(0.0001))(inputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 3), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = Convolution3D(16, 1, 1, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='lecun_uniform', W_regularizer=l2(0.0001))(cinputs)\n",
    "        cinputs = Convolution3D(32, 2, 2, 2, border_mode='same', subsample=(1, 1, 1), activation='relu',init='lecun_uniform', W_regularizer=l2(0.0001))(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        f1 = Flatten()(cinputs)\n",
    "        f1 = Dense(output_dim=32, activation='relu', init='lecun_uniform', W_regularizer=l2(0.0001))(f1)\n",
    "        f1 = Dropout(.7)(f1)\n",
    "\n",
    "        inc_output = Dense(output_dim=1, activation='sigmoid',init='normal', W_regularizer=l2(0.0002))(f1)\n",
    "        incep = Model(inputs, inc_output)\n",
    "\n",
    "        incep.compile(loss='binary_crossentropy',\n",
    "                      optimizer=Nadam(lr=0.0005, beta_1=0.9, beta_2=0.999,\n",
    "                                      epsilon=1e-08, schedule_decay=0.005), metrics=['accuracy'])\n",
    "\n",
    "        lcallbacks = [callbacks.ModelCheckpoint('models/conv3d_classifier_stc.h5', monitor='val_loss', save_best_only=True, mode='min')]\n",
    "            #callbacks.EarlyStopping(monitor='val_loss', patience=20, mode='min'), \n",
    "            \n",
    "    incep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34000 samples, validate on 4000 samples\n",
      "Epoch 1/40\n",
      "34000/34000 [==============================] - 19s - loss: 0.6718 - acc: 0.5801 - val_loss: 0.6944 - val_acc: 0.5000\n",
      "Epoch 2/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.5872 - acc: 0.7072 - val_loss: 1.0680 - val_acc: 0.5000\n",
      "Epoch 3/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.5458 - acc: 0.7454 - val_loss: 2.2841 - val_acc: 0.5000\n",
      "Epoch 4/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.5207 - acc: 0.7671 - val_loss: 0.5424 - val_acc: 0.7400\n",
      "Epoch 5/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.5027 - acc: 0.7796 - val_loss: 0.5074 - val_acc: 0.7595\n",
      "Epoch 6/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4910 - acc: 0.7879 - val_loss: 0.4916 - val_acc: 0.7710\n",
      "Epoch 7/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4788 - acc: 0.7956 - val_loss: 0.4823 - val_acc: 0.7822\n",
      "Epoch 8/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4673 - acc: 0.8022 - val_loss: 0.4848 - val_acc: 0.7797\n",
      "Epoch 9/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4556 - acc: 0.8111 - val_loss: 0.4933 - val_acc: 0.7790\n",
      "Epoch 10/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4506 - acc: 0.8150 - val_loss: 0.5249 - val_acc: 0.7812\n",
      "Epoch 11/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4383 - acc: 0.8221 - val_loss: 0.5010 - val_acc: 0.7870\n",
      "Epoch 12/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4296 - acc: 0.8263 - val_loss: 0.5132 - val_acc: 0.7735\n",
      "Epoch 13/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4191 - acc: 0.8307 - val_loss: 0.5277 - val_acc: 0.7520\n",
      "Epoch 14/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4182 - acc: 0.8326 - val_loss: 0.5241 - val_acc: 0.7752\n",
      "Epoch 15/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4087 - acc: 0.8376 - val_loss: 0.5105 - val_acc: 0.7825\n",
      "Epoch 16/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.4017 - acc: 0.8387 - val_loss: 0.5255 - val_acc: 0.7725\n",
      "Epoch 17/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.3933 - acc: 0.8466 - val_loss: 0.5949 - val_acc: 0.7763\n",
      "Epoch 18/40\n",
      "34000/34000 [==============================] - 16s - loss: 0.3881 - acc: 0.8485 - val_loss: 0.7605 - val_acc: 0.6678\n",
      "Epoch 19/40\n",
      " 7000/34000 [=====>........................] - ETA: 11s - loss: 0.3695 - acc: 0.8584"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4136a0f66b14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jrenner/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrenner/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrenner/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrenner/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrenner/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrenner/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/jrenner/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jrenner/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = incep.fit(x_t, y_t, shuffle=True, nb_epoch=40, batch_size=100, verbose=1, validation_data=(x_v, y_v), callbacks=lcallbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 1s     \n",
      "[0.48232511568069458, 0.78225]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = incep.evaluate(x_v, y_v);\n",
    "y_pred = incep.predict(x_v, batch_size=32, verbose=0)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results: 1761 of 2000 (88.05%) correctly predicted background events; 1084 of 2000 (54.2%) correctly predicted signal events\n"
     ]
    }
   ],
   "source": [
    "thh = 0.751\n",
    "nts = 0; ntb = 0\n",
    "ncs = 0; ncb = 0\n",
    "for yv,yp in zip(y_v,y_pred):\n",
    "    if(yv == 0):\n",
    "        ntb += 1  # add one background event\n",
    "        if(yp < thh):\n",
    "            ncb += 1  # add one correctly predicted background event\n",
    "    \n",
    "    if(yv == 1):\n",
    "        nts += 1  # add one signal event\n",
    "        if(yp >= thh):\n",
    "            ncs += 1  # add one correctly predicted signal event\n",
    "            \n",
    "print(\"Final results: {0} of {1} ({2}%) correctly predicted background events; {3} of {4} ({5}%) correctly predicted signal events\".format(ncb,ntb,1.0*ncb/ntb*100,ncs,nts,1.0*ncs/nts*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incep.save('models/largenet_noise.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the energies of the training events.\n",
    "esums = []\n",
    "for earr in s_earray:\n",
    "    esums.append(np.sum(earr)/12.)\n",
    "#for earr in b_earray:\n",
    "#    esums.append(np.sum(earr))\n",
    "    \n",
    "fig = plt.figure();\n",
    "ax1 = fig.add_subplot(111);\n",
    "fig.set_figheight(5.0)\n",
    "fig.set_figwidth(7.5)\n",
    "\n",
    "plt.hist(esums, 100, normed=1, facecolor='green')\n",
    "plt.xlabel('Cathode charge')\n",
    "plt.ylabel('Counts/bin')\n",
    "plt.show()\n",
    "print(b_earray[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carried over from NEW_kr_diff_mc_train.ipynb\n",
    "def NEW_SiPM_map_plot(xarr, yarr, plot_truth=True, normalize=True):\n",
    "    \"\"\"\n",
    "    Plots a SiPM map in the NEW Geometry\n",
    "    xarr is a NEW sipm map, yarr the pair of coordinates the map corresponds to\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        probs = (xarr - np.min(xarr))\n",
    "        probs /= np.max(probs)\n",
    "    else: \n",
    "        probs = xarr\n",
    "\n",
    "    fig = plt.figure();\n",
    "    ax1 = fig.add_subplot(111);\n",
    "    fig.set_figheight(7.0)\n",
    "    fig.set_figwidth(7.0)\n",
    "    ax1.axis([-250, 250, -250, 250]);\n",
    "\n",
    "    for i in range(48):\n",
    "        for j in range(48):\n",
    "            r = Ellipse(xy=(i * 10 - 235, j * 10 - 235), width=2., height=2.);\n",
    "            r.set_facecolor('0');\n",
    "            r.set_alpha(probs[i, j]);\n",
    "            ax1.add_artist(r);\n",
    "            \n",
    "    if plot_truth:\n",
    "        # Place a large blue circle for actual EL points.\n",
    "        xpt = yarr[0]\n",
    "        ypt = yarr[1]\n",
    "        mrk = Ellipse(xy=(xpt,ypt), width=4., height=4.);\n",
    "        mrk.set_facecolor('b');\n",
    "        ax1.add_artist(mrk);\n",
    "        #print(xpt,ypt)\n",
    "        \n",
    "    plt.xlabel(\"x (mm)\");\n",
    "    plt.ylabel(\"y (mm)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot training event slices.\n",
    "plt_nevt = 14900\n",
    "plt_nslice = 5\n",
    "\n",
    "plt_arr = x_t[plt_nevt,:,:,plt_nslice]\n",
    "NEW_SiPM_map_plot(plt_arr,[0, 0], False)\n",
    "chg_sum = np.sum(plt_arr)\n",
    "tot_chg_sum = np.sum(x_t[plt_nevt,:,:,:])\n",
    "max_chg = np.max(x_t[plt_nevt,:,:,plt_nslice])\n",
    "min_chg = np.min(x_t[plt_nevt,:,:,plt_nslice])\n",
    "print(\"Plotting event\", plt_nevt, \"slice\", plt_nslice, \"with charge sum\", chg_sum, \"and total sum\", tot_chg_sum,\n",
    "     \"max charge\", max_chg, \"and min charge\", min_chg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return a histogram containing the SiPM distribution for a given (x,y,z), where x,y,z are indices in the map.\n",
    "def SiPM_dist(sipm_maps,x,y,z):\n",
    "    \n",
    "    return sipm_maps[:,x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine which SiPMs have all-zero distributions for a given slice.\n",
    "slnum = 0\n",
    "for sipmx in range(48):\n",
    "    for sipmy in range(48):\n",
    "        \n",
    "        dist = x_t[:,sipmx,sipmy,slnum]\n",
    "        nzeros = len(np.nonzero(dist)[0])\n",
    "        if(nzeros == 0):\n",
    "            print(\"All zeros for SiPM ({0},{1})\".format(sipmx,sipmy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot 12 distributions.\n",
    "fig = plt.figure();\n",
    "fig.set_figheight(20.0)\n",
    "fig.set_figwidth(13.0)\n",
    "\n",
    "for ndist in range(3):\n",
    "    sp = int(430 + ndist + 1)\n",
    "    print(\"plot\",sp)\n",
    "    ax = fig.add_subplot(sp);\n",
    "    \n",
    "    xv = np.random.randint(38) + 5\n",
    "    yv = np.random.randint(38) + 5 \n",
    "    sv = np.random.randint(14)\n",
    "\n",
    "    dist = x_t[:,xv,yv,sv]\n",
    "    plt.hist(dist[np.nonzero(dist)], 1000, normed=0, facecolor='green')\n",
    "    ax.set_yscale('log')\n",
    "    start, end = ax.get_xlim()\n",
    "    #ax.xaxis.set_ticks(np.arange(start, end, (end-start)/4.))\n",
    "    plt.xlim(0.0,0.05)\n",
    "    plt.xlabel('SiPM Charge')\n",
    "    plt.ylabel('Counts/bin')\n",
    "    plt.title('SiPM ({0},{1}); slice {2}'.format(xv,yv,sv))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(x_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Old nets\n",
    "        cinputs = Convolution3D(32, 6, 6, 6, border_mode='same', subsample=(3, 3, 5), activation='relu',init='normal', W_regularizer=l2(0.001))(inputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 3), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = Convolution3D(16, 1, 1, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        cinputs = Convolution3D(32, 2, 2, 2, border_mode='same', subsample=(1, 1, 1), activation='relu',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        \n",
    "        \n",
    "\n",
    "        inputs = Input(shape=(48, 48, 30, 1))\n",
    "        cinputs = Convolution3D(512, 6, 6, 6, border_mode='same', subsample=(3, 3, 5), activation='relu',init='normal', W_regularizer=l2(0.001))(inputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 3), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = Convolution3D(64, 1, 1, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        cinputs = Convolution3D(1024, 2, 2, 2, border_mode='same', subsample=(1, 1, 1), activation='relu',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = Convolution3D(16, 1, 1, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        #cinputs = Convolution3D(16, 3, 3, 3, border_mode='same', subsample=(2, 2, 2), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(32, 3, 3, 3, border_mode='same', subsample=(2, 2, 5), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(64, 2, 2, 2, border_mode='same', subsample=(2, 2, 1), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(512, 2, 2, 2, border_mode='same', subsample=(2, 2, 5), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(1024, 2, 2, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(1024, 2, 2, 1, border_mode='valid', subsample=(3, 3, 1), activation='relu')(cinputs)\n",
    "        f1 = Flatten()(cinputs)\n",
    "        f1 = Dense(output_dim=1024, activation='relu', init='normal', W_regularizer=l2(0.001))(f1)\n",
    "        f1 = Dropout(.4)(f1)\n",
    "\n",
    "        inc_output = Dense(output_dim=1, activation='sigmoid',init='normal')(f1)\n",
    "        incep = Model(inputs, inc_output)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        cinputs = Convolution3D(32, 6, 6, 6, border_mode='same', subsample=(3, 3, 5), activation='sigmoid',init='normal', W_regularizer=l2(0.001))(inputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 3), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        #cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        #cinputs = Convolution3D(64, 1, 1, 1, border_mode='same', subsample=(1, 1, 1), activation='tanh',init='normal')(cinputs)\n",
    "        cinputs = Convolution3D(64, 2, 2, 2, border_mode='same', subsample=(1, 1, 1), activation='sigmoid',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        #cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        #cinputs = Convolution3D(16, 1, 1, 1, border_mode='same', subsample=(1, 1, 1), activation='tanh',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(16, 3, 3, 3, border_mode='same', subsample=(2, 2, 2), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(32, 3, 3, 3, border_mode='same', subsample=(2, 2, 5), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(64, 2, 2, 2, border_mode='same', subsample=(2, 2, 1), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(512, 2, 2, 2, border_mode='same', subsample=(2, 2, 5), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(1024, 2, 2, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(1024, 2, 2, 1, border_mode='valid', subsample=(3, 3, 1), activation='relu')(cinputs)\n",
    "\n",
    "        inputs = Input(shape=(48, 48, 30))\n",
    "        cinputs = Convolution2D(512, 6, 6, border_mode='same', subsample=(3, 3), activation='relu',init='normal', W_regularizer=l2(0.001))(inputs)\n",
    "        cinputs = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=3, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = Convolution2D(64, 1, 1, border_mode='same', subsample=(1, 1), activation='relu',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        cinputs = Convolution2D(1024, 2, 2, border_mode='same', subsample=(1, 1), activation='relu',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = Convolution2D(16, 1, 1, border_mode='same', subsample=(1, 1), activation='relu',init='normal', W_regularizer=l2(0.001))(cinputs)\n",
    "        \n",
    "        # 2D net 16-12-16\n",
    "        inputs = Input(shape=(48, 48, 30))\n",
    "        cinputs = Convolution2D(32, 6, 6, border_mode='same', subsample=(3, 3), activation='relu',init='lecun_uniform', W_regularizer=l2(0.01))(inputs)\n",
    "        cinputs = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=3, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        #cinputs = Convolution2D(8, 1, 1, border_mode='same', subsample=(1, 1), activation='relu',init='lecun_uniform', W_regularizer=l2(0.05))(cinputs)\n",
    "        cinputs = Convolution2D(64, 2, 2, border_mode='same', subsample=(1, 1), activation='relu',init='lecun_uniform', W_regularizer=l2(0.01))(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=3, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = Convolution2D(128, 1, 1, border_mode='same', subsample=(1, 1), activation='relu',init='lecun_uniform', W_regularizer=l2(0.01))(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=3, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        f1 = Flatten()(cinputs)\n",
    "        f1 = Dense(output_dim=128, activation='relu', init='lecun_uniform', W_regularizer=l2(0.008))(f1)\n",
    "        f1 = Dropout(.6)(f1)\n",
    "\n",
    "        inc_output = Dense(output_dim=1, activation='sigmoid',init='lecun_uniform', W_regularizer=l2(0.001))(f1)\n",
    "        incep = Model(inputs, inc_output)\n",
    "        \n",
    "        # Good 3D net 16-12-16\n",
    "        inputs = Input(shape=(48, 48, 30, 1))\n",
    "        cinputs = Convolution3D(128, 6, 6, 6, border_mode='same', subsample=(3, 3, 5), activation='relu',init='lecun_uniform', W_regularizer=l2(0.01))(inputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(3, 3, 3), strides=(2, 2, 3), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = Convolution3D(64, 1, 1, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='lecun_uniform', W_regularizer=l2(0.01))(cinputs)\n",
    "        cinputs = Convolution3D(128, 2, 2, 2, border_mode='same', subsample=(1, 1, 1), activation='relu',init='lecun_uniform', W_regularizer=l2(0.01))(cinputs)\n",
    "        cinputs = BatchNormalization(epsilon=1e-05, mode=0, axis=4, momentum=0.99, weights=None, beta_init='zero', gamma_init='one', gamma_regularizer=None, beta_regularizer=None)(cinputs)\n",
    "        cinputs = MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), border_mode='same', dim_ordering='default')(cinputs)\n",
    "        #cinputs = Convolution3D(16, 1, 1, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='lecun_uniform', W_regularizer=l2(0.01))(cinputs)\n",
    "        #cinputs = Convolution3D(16, 3, 3, 3, border_mode='same', subsample=(2, 2, 2), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(32, 3, 3, 3, border_mode='same', subsample=(2, 2, 5), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(64, 2, 2, 2, border_mode='same', subsample=(2, 2, 1), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(512, 2, 2, 2, border_mode='same', subsample=(2, 2, 5), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(1024, 2, 2, 1, border_mode='same', subsample=(1, 1, 1), activation='relu',init='normal')(cinputs)\n",
    "        #cinputs = Convolution3D(1024, 2, 2, 1, border_mode='valid', subsample=(3, 3, 1), activation='relu')(cinputs)\n",
    "        f1 = Flatten()(cinputs)\n",
    "        f1 = Dense(output_dim=64, activation='relu', init='lecun_uniform', W_regularizer=l2(0.02))(f1)\n",
    "        f1 = Dropout(.7)(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add noise\n",
    "nsigma = 1.0e-4\n",
    "\n",
    "inoise = x_t == 0.\n",
    "x_t[inoise] = np.abs(np.random.normal(0,1.0e-4,np.sum(inoise)))\n",
    "\n",
    "inoise = x_v == 0.\n",
    "x_v[inoise] = np.abs(np.random.normal(0,1.0e-4,np.sum(inoise)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
